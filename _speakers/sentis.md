---
title: "Luis Sentis"
excerpt: "From Model-Based Whole-Body Control to Humanoid Legged Manipulation using Machine Learning"
layout: single 
classes: wide
permalink: /sentis/

sidebar:
  - title: "Professor"
    image: /docs/assets/images/speakers/sentis.jpeg 
    image_alt: "logo"
    text: "University of Texas at Austin"

toc: false 
collection: speakers
---
[Luis Sentis](https://www.ae.utexas.edu/people/faculty/faculty-directory/sentis) is a Professor in the Department of Aerospace Engineering and Engineering Mechanics at The University of Texas at Austin. He is also a General Dynamics Endowed Faculty Fellow, and a member of UT Austin's Good Systems. He received his Ph.D. and M.S. degrees in Electrical Engineering from Stanford University. He was a La Caixa Foundation Fellow while at Stanford. He holds a B.S. degree in Telecommunications and Electronics Engineering from the Polytechnic University of Catalonia. Before Stanford, he worked in Silicon Valley as a Control Systems Engineer for clean room automation.

In Austin, he leads the Human Centered Robotics Laboratory, a laboratory focusing on control, task and motion planning, human factors, and experimentation with humanoid robots, mobile manipulation robots, exoskeletons and autonomous systems. He is also a founding member of the UT Robotics Portfolio Program and the UT Ethics of AI Portfolio Program. He was the UT Austin's Lead for DARPA's Robotics Challenge with NASA Johnson Space Center where he helped to design and test the Valkyrie humanoid robot. His research has been funded by ONR, NASA, NSF, ARL, AFC, DARPA and private companies.

He has been awarded the NASA Elite Team Award for his contributions to NASAâ€™s Johnson Space Center Software Robotics and Simulation Division. He is also a founding member and innovation advisor for Apptronik Systems, a company focusing on human-centered robotic products.

<center style="font-size:30px">
From Model-Based Whole-Body Control to Humanoid Legged Manipulation using Machine Learning
</center>



##### Abstract

WBC controllers have provided unique capabilities for humanoid robots such as multicontact and dynamically and kinematically consistent motion tracking for humanoid robots. In combination with trajectory optimization predictive methods, WBCs have enabled outstanding agile behaviors. However, to operate in truly unstructured environments, machine learning techniques are needed to provide humanoid legged manipulation policies that take as input the large state space given by exteroceptive sensors such as cameras and tactile sensors. In this presentation I will discuss the onset of WBCs and the current success for perceptive legged manipulation using machine learning techniques. Experiments using the DRACO 3 humanoid robot will be shown. 


